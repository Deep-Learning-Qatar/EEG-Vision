# -*- coding: utf-8 -*-
"""Mapping_Net.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ESLUiFITqGcI8H0XXOkt9FMaqzZ_Jlvd

# **Connect to drive and set-up other stuff**
"""


"""# **Import required Libraries**"""

import os
import time
import torch
import numpy as np
import torch.nn as nn
from torch.utils import data
import matplotlib.pyplot as plt
from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence
import copy


"""# **MyDataset Class**"""

class MyDataset(data.Dataset):

    def __init__(self, X_path, Y_path, class_labels_path):
        self.X = np.load(X_path, allow_pickle=True)
        self.Y = np.load(Y_path, allow_pickle=True)
        self.class_labels = np.load(class_labels_path, allow_pickle=True)

        # Total number of frames
        self.length = self.Y.shape[0]

    def __len__(self):
        return self.length

    def __getitem__(self, index):
        d = torch.as_tensor(self.X[index]).float()
        l = torch.as_tensor(self.Y[index]).float()
        c = torch.as_tensor(self.class_labels[index]).long()
        return d, l, c
    

class MyDataset_test(data.Dataset):
    def __init__(self, X_path):
        self.X = np.load(X_path, allow_pickle=True)
        
        # Total number of frames
        self.length = self.X.shape[0]
        
    def __len__(self):
        return self.length
    
    def __getitem__(self, index):
        d = torch.as_tensor(self.X[index]).float()
        return d

"""# **Architecture of Bi-LSTM**"""

# There is a lot of exprimental additions here (BN, dropout, type of embiddings layers, ...) 

class BiLSTM(nn.Module):
    def __init__(self, embiddings_num, hidden_size, num_classes, n_layers, bidirectional, dropout):
        super().__init__()
        
        # sequence input layer
        layers1 = []
        layers1.append(nn.Conv1d(embiddings_num, hidden_size, 3, padding=1, bias=False))
        layers1.append(nn.BatchNorm1d(hidden_size))
        layers1.append(nn.ReLU(inplace=True))
        self.embid = nn.Sequential(*layers1)

        # Stacked BiLSTM netwrok
        self.lstm = nn.LSTM(hidden_size,
                            hidden_size,
                            num_layers=n_layers,
                            bidirectional=bidirectional,
                            batch_first=True,
                            dropout=dropout,
                            bias=True)

        # Fully connected layer
        self.fc = nn.Sequential(nn.Linear(hidden_size * 2, hidden_size),
                                nn.Linear(hidden_size, num_classes))


    def forward(self, x): 
        # X: (B x T x *)

        x = x[:, None, :]
        
        # preprocessing to pass it to CNN (B x * x T)
        x2 = x.permute(0, 2, 1)                               # (B x * x T)

        # Through CNN
        embedded = self.embid(x2)                             # (B x * x T)

        # Through BiLSTM
        x3 = embedded.permute(0, 2, 1)                        # (B x T x *)
        output, (hidden, cell) = self.lstm(x3)          # (B x T x *)

        #classify and apply softmax
        features_out = self.fc(output)                        # (B x T x *)

        # class_out = features_out.log_softmax(2)             # (B x T x *) 

        return features_out.permute(1, 0, 2)                  # (T X B x *)

class Simple_MLP(nn.Module):
  def __init__(self, size_list, dropout_prob):
    super(Simple_MLP, self).__init__()
    layers = []

    # Construct the NN
    for i in range(len(size_list) - 2):
      layers.append(nn.Linear(size_list[i], size_list[i+1]))
      layers.append(nn.BatchNorm1d(num_features=size_list[i+1]))
      layers.append(nn.ReLU())
      layers.append(nn.Dropout(p=dropout_prob, inplace=False))
      
    layers.append(nn.Linear(size_list[-2], size_list[-1]))
    self.net = nn.Sequential(*layers)

  def forward(self, x):
    return self.net(x)

"""# Module functions """
def make_EEG_Image_data_loaders(config):

    # Training Data Loader
    train_dataset = MyDataset(config.train_data_path, config.train_labels_path, config.train_class_labels_path)
    train_loader_args = dict(shuffle=True, batch_size=config.batch_size, num_workers=2) 
    train_loader = data.DataLoader(train_dataset, **train_loader_args)

    train_loader_unshuffle_args = dict(shuffle=False, batch_size=config.batch_size, num_workers=2)
    train_loader_unshuffle = data.DataLoader(train_dataset, **train_loader_unshuffle_args)

    # Validation Data Loader
    val_dataset = MyDataset(config.val_data_path, config.val_labels_path, config.val_class_labels_path)
    val_loader_args = dict(shuffle=False, batch_size=config.batch_size, num_workers=2)
    val_loader = data.DataLoader(val_dataset, **val_loader_args)

    # Testing Data Loader
    test_dataset = MyDataset(config.test_data_path, config.test_labels_path, config.test_class_labels_path)
    test_loader_args = dict(shuffle=False, batch_size=config.batch_size, num_workers=2)
    test_loader = data.DataLoader(test_dataset, **test_loader_args)

    dataloaders_dict = dict(
        train=train_loader,
        train_unshuffle=train_loader_unshuffle,
        val=val_loader,
        test=test_loader,
    )

    return dataloaders_dict

def make_EEG_Image_Map(config):

    dataloaders = make_EEG_Image_data_loaders(config)

    """# **Set up the model**"""
    if config.model == 'mlp':
        model = Simple_MLP(config.mlp_layers, config.dropout_prob)
    elif config.model == 'bilstm':
        model = BiLSTM(config.embiddings_num, config.hidden_size, config.num_classes, config.num_layers, config.bidirectional, config.dropout_prob)
    else:
        model = None

    if config.criterion == 'cosine':
        criterion = nn.CosineEmbeddingLoss()
    elif config.criterion == 'mae':
        criterion = nn.L1Loss()
    else:
        criterion = nn.MSELoss(reduction='none')
    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.wd)
    if config.scheduler == 'steplr':
        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, config.step_size, gamma=config.scheduler_factor, verbose=True)
    else:
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=config.scheduler_factor, patience=config.patience, verbose=True)                

    model.cuda()

    return model, dataloaders, criterion, optimizer, scheduler

def train_and_val_EEG_Image_Map(wandb, config, model, dataloaders, criterion, optimizer, scheduler, num_epochs=50):

    since = time.time()

    val_loss_history = []

    best_model_wts = copy.deepcopy(model.state_dict())
    best_loss = 1000000
    epoch_loss = None

    for epoch in range(num_epochs):
        if epoch%(int(num_epochs/10)) == 1:
            print('Epoch {}/{}'.format(epoch+1, num_epochs))
            print('-' * 10)

        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode

            running_loss = 0.0

            # Iterate over data.
            for inputs, labels, _ in dataloaders[phase]:
                inputs = inputs.cuda()
                labels = labels.cuda()

                # zero the parameter gradients
                optimizer.zero_grad()

                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    # Run data through the model, Compare output to target
                    outputs = model(inputs).squeeze()        # (T x B x *)
                    
                    if config.criterion == 'cosine':
                        loss = criterion(outputs, labels, torch.ones(len(outputs)).cuda())
                    else:
                        loss = criterion(outputs, labels)

                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                # statistics
                running_loss += loss.item() * inputs.size(0)

            epoch_loss = running_loss / len(dataloaders[phase].dataset)

            if phase == 'train':
                wandb.log({"epoch": epoch, "train_loss": epoch_loss})
            elif phase == 'val':
                wandb.log({"epoch": epoch, "val_loss": epoch_loss})
            else:
                print('Did not log')
            
            if epoch%(int(num_epochs/10)) == 1:
                print('[{}] Loss: {:.4f}'.format(phase, epoch_loss))

            # deep copy the model
            if phase == 'val' and epoch_loss < best_loss:
                best_loss = epoch_loss
                best_model_wts = copy.deepcopy(model.state_dict())
            if phase == 'val':
                val_loss_history.append(epoch_loss)

        # Save model every epoch
        filename = 'EEGImageMap' + str(config['model_nr']) + 'epoch' + str(epoch+1) + '.pth'
        torch.save(model.state_dict(), filename)

        if config.scheduler == 'plateau':
            scheduler.step(epoch_loss)
        elif config.scheduler == 'steplr':
            scheduler.step()

    time_elapsed = time.time() - since
    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))
    print('Best val Loss: {:4f}'.format(best_loss))

    # load best model weights
    model.load_state_dict(best_model_wts)
    return model, val_loss_history

def test_EEG_Image_Map(model, test_loader):
    model.eval()

    # Run the model on some test examples
    with torch.no_grad():
        predictions = []

        for inputs, labels, _ in test_loader:
            inputs = inputs.cuda()
            
            outputs = model(inputs).squeeze()

            predictions.append(outputs.cpu().numpy())
            
            del inputs

        return predictions

def get_id_indx(feature, feature_list, true_indx):
  cos = nn.CosineSimilarity(dim=0)

  # set the first image feature as the best seen so far 
  best_indx = 0
  best_cos = torch.mean(cos(feature, feature_list[0])).item()
  real_cos = 0.

  for indx, f in enumerate(feature_list):
    current_cos = torch.mean(cos(feature, f)).item()
    if current_cos > best_cos:
        best_indx = indx
        best_cos = current_cos
    if indx == true_indx:
        real_cos = current_cos

  return best_indx, real_cos

def calc_map_metrics(outputs, test_loader):
    """ Calculates metrics to evaluate map """
    correct_id = 0.
    correct_class = 0.
    all_labels = []
    all_class_labels = []

    # make list out of labels and class_labels in data_loader
    for inputs, labels, class_labels in test_loader:
        all_labels.append(labels.cpu())
        all_class_labels.append(class_labels.cpu())
    
    all_labels_flat = [item for sublist in all_labels for item in sublist]
    all_class_labels_flat = [item for sublist in all_class_labels for item in sublist]

    del all_labels
    del all_class_labels

    similarities = []

    # loop through each outputs and 
    for indx, out in enumerate(outputs):
        out_indx, real_cos = get_id_indx(torch.as_tensor(out).float(), all_labels_flat, indx)
        if indx == out_indx:
            correct_id += 1
        if all_class_labels_flat[indx] == all_class_labels_flat[out_indx]:
            correct_class += 1
        similarities.append(real_cos)

    acc_id = correct_id / len(all_labels_flat)
    acc_class = correct_class / len(all_class_labels_flat)
    
    return acc_id, acc_class, similarities
