{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "HsPwA-QsZ-0o"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4aa37adc41b24572b3a717607dc5cb90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_07a51ac588ea49cea96fe49013dfdd9a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8b2c50652fd74913bc0f069e3a40a717",
              "IPY_MODEL_ac4e1b3b094c46d2956663d856c8a3e3"
            ]
          }
        },
        "07a51ac588ea49cea96fe49013dfdd9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b2c50652fd74913bc0f069e3a40a717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_be681e4e899b43f088fb40afd8f052ab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd8cbe6cf23f4982ad0fd78c2f7d339e"
          }
        },
        "ac4e1b3b094c46d2956663d856c8a3e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b4c125d06a544dc48eef7326d9de8c9f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c0707955780f4534ad0da828ee22e104"
          }
        },
        "be681e4e899b43f088fb40afd8f052ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd8cbe6cf23f4982ad0fd78c2f7d339e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b4c125d06a544dc48eef7326d9de8c9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c0707955780f4534ad0da828ee22e104": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98a44a7417214a13a3d025e76b52ff5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e538f8c15ba24d80a1705f926e4b7097",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_782e2dbfc4c248d38d28bf5ac94fb5c5",
              "IPY_MODEL_e2656afbac71467d983b1aa98d0f701c"
            ]
          }
        },
        "e538f8c15ba24d80a1705f926e4b7097": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "782e2dbfc4c248d38d28bf5ac94fb5c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_bf301baf612947a7a6ab79e700bccee9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f1d5a67d50e0420fb5c57acf4b0bdf88"
          }
        },
        "e2656afbac71467d983b1aa98d0f701c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_07963184003e4124bac3b2390c440a20",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5589648c6c8742ddb1586eb2e392b50d"
          }
        },
        "bf301baf612947a7a6ab79e700bccee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f1d5a67d50e0420fb5c57acf4b0bdf88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "07963184003e4124bac3b2390c440a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5589648c6c8742ddb1586eb2e392b50d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deep-Learning-Qatar/EEG-Vision/blob/master/Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scx-gSmjVLzI"
      },
      "source": [
        "**Pipeline**: This is a general set-up to evaluate our entire EEG-Vision predictive system using the thre individual models that are imported to maximize modularity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifwnKzPRVw5u",
        "outputId": "728e66e6-0ec7-44fd-b4ff-eb8069bdb5af"
      },
      "source": [
        "# mount gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npwvO3l5Vm6B"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR4pEnTZV9ct"
      },
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils import data\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOx67bxlhhUi",
        "outputId": "ca686582-c6da-4943-e99c-31a12b57f020"
      },
      "source": [
        "# install and import wandb\n",
        "!pip install wandb --upgrade\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: wandb in /usr/local/lib/python3.7/dist-packages (0.10.29)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: sentry-sdk>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied, skipping upgrade: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied, skipping upgrade: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.0.2)\n",
            "Requirement already satisfied, skipping upgrade: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.14)\n",
            "Requirement already satisfied, skipping upgrade: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (56.0.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n",
            "Requirement already satisfied, skipping upgrade: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (4.0.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msbaumann\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCFyPiCok_P7",
        "outputId": "e967de0c-46b4-46cb-c832-0587f8b9e09c"
      },
      "source": [
        "%cd /gdrive/MyDrive/11-785 Deep Learning/Project\n",
        "\n",
        "# path to data\n",
        "EEG_dataset_path = '/gdrive/MyDrive/11-785 Deep Learning/Project/EEG_datasets.pth'\n",
        "Image_dataset_path = '/gdrive/MyDrive/11-785 Deep Learning/Project/data_by_image.pth'\n",
        "\n",
        "from eeg_net import make_EEG_Net, train_and_val_EEG_Net, test_EEG_Net\n",
        "from image_net import make_Image_Net, train_and_val_Image_Net, test_Image_Net, make_EEG_to_Image_data_loaders\n",
        "from eeg_image_map import make_EEG_Image_Map, train_and_val_EEG_Image_Map, test_EEG_Image_Map, calc_feature_id_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/MyDrive/11-785 Deep Learning/Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEUQ5yv_lbPz"
      },
      "source": [
        "# Pipeline (EEG-Net and Image-Net)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eLlAw6Clgwd"
      },
      "source": [
        "def model_pipeline_EEG_Net(hyperparameters):\n",
        "    %cd /gdrive/MyDrive/11-785 Deep Learning/Project\n",
        "\n",
        "    with wandb.init(project='EEG-Net', entity='eegvision', config=hyperparameters):\n",
        "      config = wandb.config\n",
        "      model, EEG_data_loaders, criterion, optimizer, scheduler = make_EEG_Net(config, EEG_dataset_path)\n",
        "\n",
        "      %cd EEG-Net\n",
        "      model, val_acc_hist = train_and_val_EEG_Net(wandb, config, model, EEG_data_loaders, criterion, optimizer, scheduler, num_epochs=config.num_epochs)\n",
        "\n",
        "    return model, EEG_data_loaders, val_acc_hist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831,
          "referenced_widgets": [
            "4aa37adc41b24572b3a717607dc5cb90",
            "07a51ac588ea49cea96fe49013dfdd9a",
            "8b2c50652fd74913bc0f069e3a40a717",
            "ac4e1b3b094c46d2956663d856c8a3e3",
            "be681e4e899b43f088fb40afd8f052ab",
            "fd8cbe6cf23f4982ad0fd78c2f7d339e",
            "b4c125d06a544dc48eef7326d9de8c9f",
            "c0707955780f4534ad0da828ee22e104"
          ]
        },
        "id": "tJ-_CZpga1yp",
        "outputId": "34fc67eb-d14f-4451-ce58-fcb7069d55c2"
      },
      "source": [
        "EEG_hyperparams = dict(\n",
        "    model_nr = 2,\n",
        "\n",
        "    # Models to choose from [fares]\n",
        "    model = \"fares\",\n",
        "\n",
        "    # Number of classes in the dataset\n",
        "    num_classes = 40,\n",
        "\n",
        "    # Number of epochs to train for\n",
        "    num_epochs = 1,\n",
        "\n",
        "    lr = 0.005,\n",
        "    weight_decay = 5e-6,\n",
        "    dropout = 0.3\n",
        ")\n",
        "\n",
        "EEG_Net, EEG_data_loaders, eeg_acc_hist = model_pipeline_EEG_Net(EEG_hyperparams)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/MyDrive/11-785 Deep Learning/Project\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.29<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">distinctive-oath-25</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/eegvision/EEG-Net\" target=\"_blank\">https://wandb.ai/eegvision/EEG-Net</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/eegvision/EEG-Net/runs/jptkbrp7\" target=\"_blank\">https://wandb.ai/eegvision/EEG-Net/runs/jptkbrp7</a><br/>\n",
              "                Run data is saved locally in <code>/gdrive/MyDrive/11-785 Deep Learning/Project/wandb/run-20210505_121745-jptkbrp7</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/gdrive/MyDrive/11-785 Deep Learning/Project/EEG-Net\n",
            "Epoch 1/1\n",
            "----------\n",
            "[train] Loss: 3.6624 Acc: 0.0371\n",
            "[val] Loss: 3.5527 Acc: 0.0377\n",
            "\n",
            "Training complete in 0m 9s\n",
            "Best val Acc: 0.037688\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 2517<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4aa37adc41b24572b3a717607dc5cb90",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/gdrive/MyDrive/11-785 Deep Learning/Project/wandb/run-20210505_121745-jptkbrp7/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/gdrive/MyDrive/11-785 Deep Learning/Project/wandb/run-20210505_121745-jptkbrp7/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>0</td></tr><tr><td>train_loss</td><td>3.66243</td></tr><tr><td>train_acc</td><td>0.03706</td></tr><tr><td>_runtime</td><td>59</td></tr><tr><td>_timestamp</td><td>1620217124</td></tr><tr><td>_step</td><td>1</td></tr><tr><td>val_loss</td><td>3.55271</td></tr><tr><td>val_acc</td><td>0.03769</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>train_acc</td><td>▁</td></tr><tr><td>_runtime</td><td>▁█</td></tr><tr><td>_timestamp</td><td>▁█</td></tr><tr><td>_step</td><td>▁█</td></tr><tr><td>val_loss</td><td>▁</td></tr><tr><td>val_acc</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">distinctive-oath-25</strong>: <a href=\"https://wandb.ai/eegvision/EEG-Net/runs/jptkbrp7\" target=\"_blank\">https://wandb.ai/eegvision/EEG-Net/runs/jptkbrp7</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL5F4yilaA7Q"
      },
      "source": [
        "def model_pipeline_Image_Net(hyperparameters):\n",
        "    %cd /gdrive/MyDrive/11-785 Deep Learning/Project\n",
        "\n",
        "    with wandb.init(project='Image-Net', entity='eegvision', config=hyperparameters):\n",
        "      config = wandb.config\n",
        "      model, Image_data_loaders, criterion, optimizer = make_Image_Net(config, EEG_dataset_path, Image_dataset_path)\n",
        "\n",
        "      %cd Image-Net\n",
        "      model, val_acc_hist = train_and_val_Image_Net(wandb, config, model, Image_data_loaders, criterion, optimizer,\n",
        "                                                    is_inception=(config.model_name==\"inception\"))\n",
        "\n",
        "    return model, Image_data_loaders, val_acc_hist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920,
          "referenced_widgets": [
            "98a44a7417214a13a3d025e76b52ff5c",
            "e538f8c15ba24d80a1705f926e4b7097",
            "782e2dbfc4c248d38d28bf5ac94fb5c5",
            "e2656afbac71467d983b1aa98d0f701c",
            "bf301baf612947a7a6ab79e700bccee9",
            "f1d5a67d50e0420fb5c57acf4b0bdf88",
            "07963184003e4124bac3b2390c440a20",
            "5589648c6c8742ddb1586eb2e392b50d"
          ]
        },
        "id": "E1QBzQQ2bAV0",
        "outputId": "10588873-c9a6-4c4b-e1ae-c5e104cd51f3"
      },
      "source": [
        "Image_hyperparams = dict(\n",
        "    model_nr = 1,\n",
        "\n",
        "    # Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "    model_name = \"inception\",\n",
        "\n",
        "    # Number of classes in the dataset\n",
        "    num_classes = 40,\n",
        "\n",
        "    # Batch size for training (change depending on how much memory you have)\n",
        "    batch_size = 64,\n",
        "\n",
        "    # Number of epochs to train for\n",
        "    num_epochs = 1,\n",
        "\n",
        "    # Flag for feature extracting. When False, we finetune the whole model,\n",
        "    #   when True we only update the reshaped layer params\n",
        "    feature_extract = True,\n",
        "\n",
        "    lr = 0.001,\n",
        ")\n",
        "\n",
        "Image_Net, Image_data_loaders, image_acc_hist = model_pipeline_Image_Net(Image_hyperparams)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/MyDrive/11-785 Deep Learning/Project\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.29<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">drawn-mountain-21</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/eegvision/Image-Net\" target=\"_blank\">https://wandb.ai/eegvision/Image-Net</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/eegvision/Image-Net/runs/19ey2ajd\" target=\"_blank\">https://wandb.ai/eegvision/Image-Net/runs/19ey2ajd</a><br/>\n",
              "                Run data is saved locally in <code>/gdrive/MyDrive/11-785 Deep Learning/Project/wandb/run-20210505_121847-19ey2ajd</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t AuxLogits.fc.weight\n",
            "\t AuxLogits.fc.bias\n",
            "\t fc.weight\n",
            "\t fc.bias\n",
            "/gdrive/My Drive/11-785 Deep Learning/Project/Image-Net\n",
            "Epoch 1/1\n",
            "----------\n",
            "[train] Loss: 5.1587 Acc: 0.0682\n",
            "[val] Loss: 3.4743 Acc: 0.2613\n",
            "\n",
            "Training complete in 0m 7s\n",
            "Best val Acc: 0.261307\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 2589<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98a44a7417214a13a3d025e76b52ff5c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/gdrive/MyDrive/11-785 Deep Learning/Project/wandb/run-20210505_121847-19ey2ajd/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/gdrive/MyDrive/11-785 Deep Learning/Project/wandb/run-20210505_121847-19ey2ajd/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>0</td></tr><tr><td>train_loss</td><td>5.15873</td></tr><tr><td>train_acc</td><td>0.06821</td></tr><tr><td>_runtime</td><td>105</td></tr><tr><td>_timestamp</td><td>1620217232</td></tr><tr><td>_step</td><td>1</td></tr><tr><td>val_loss</td><td>3.47426</td></tr><tr><td>val_acc</td><td>0.26131</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>train_acc</td><td>▁</td></tr><tr><td>_runtime</td><td>▁█</td></tr><tr><td>_timestamp</td><td>▁█</td></tr><tr><td>_step</td><td>▁█</td></tr><tr><td>val_loss</td><td>▁</td></tr><tr><td>val_acc</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">drawn-mountain-21</strong>: <a href=\"https://wandb.ai/eegvision/Image-Net/runs/19ey2ajd\" target=\"_blank\">https://wandb.ai/eegvision/Image-Net/runs/19ey2ajd</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6WRkkPwl2SU"
      },
      "source": [
        "# Create feature dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftG6sPtyb8VX"
      },
      "source": [
        "nr_eeg_features, nr_image_features = 128, 40"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8PY9dAPly1T"
      },
      "source": [
        "def make_feature_datasets(EEG_data_loaders, Image_data_loaders):\n",
        "    global nr_eeg_features, nr_image_features\n",
        "\n",
        "    input_size = 299 if Image_hyperparams['model_name'] == 'inception' else 224\n",
        "    new_Image_data_loaders = make_EEG_to_Image_data_loaders(EEG_data_loaders, Image_dataset_path, input_size)\n",
        "    \n",
        "    for phase in ['train_unshuffle', 'val', 'test']:\n",
        "        # Pass in train, valid, test data through EEG-Net to get EEG features\n",
        "        _, eeg_features, _ = test_EEG_Net(EEG_Net, EEG_data_loaders[phase])\n",
        "        eeg_features = [item for sublist in eeg_features for item in sublist]\n",
        "        nr_eeg_features = len(eeg_features[0])\n",
        "\n",
        "        # Pass in train, valid, test data through Image-Net to get Image features\n",
        "        _, image_features, _ = test_Image_Net(Image_Net, new_Image_data_loaders[phase])\n",
        "        image_features = [item for sublist in image_features for item in sublist]\n",
        "        nr_image_features = len(image_features[0])\n",
        "\n",
        "        data_path = phase + '_data.npy'\n",
        "        np.save(data_path, np.array(eeg_features))\n",
        "\n",
        "        labels_path = phase + '_labels.npy'\n",
        "        np.save(labels_path, np.array(image_features))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZYeLD6_mEPi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a76edf0-6d65-4819-bda6-8c4d92354ece"
      },
      "source": [
        "%cd /gdrive/MyDrive/11-785 Deep Learning/Project\n",
        "make_feature_datasets(EEG_data_loaders, Image_data_loaders)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/MyDrive/11-785 Deep Learning/Project\n",
            "nr eeg outputs: 9580\n",
            "nr eeg outputs: 9580\n",
            "nr eeg outputs: 1194\n",
            "nr eeg outputs: 1194\n",
            "nr eeg outputs: 1191\n",
            "nr eeg outputs: 1191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUi13f6oY-52"
      },
      "source": [
        "# Pipeline (EEG-Image-Map)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1BSZXuVZCPe"
      },
      "source": [
        "def model_pipeline_EEG_Image_Map(hyperparameters):\n",
        "    %cd /gdrive/MyDrive/11-785 Deep Learning/Project\n",
        "\n",
        "    with wandb.init(project='EEG-Image-Map', entity='eegvision', config=hyperparameters):\n",
        "      config = wandb.config\n",
        "      model, feature_data_loaders, criterion, optimizer, scheduler = make_EEG_Image_Map(config)\n",
        "\n",
        "      %cd EEG-Image-Map\n",
        "      model, val_acc_hist = train_and_val_EEG_Image_Map(wandb, config, model, feature_data_loaders, criterion, optimizer, scheduler)\n",
        "\n",
        "    return model, feature_data_loaders, val_acc_hist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i43ifU9Znm1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "b8200cd3-2763-47a1-f7c9-81e278cc82b2"
      },
      "source": [
        "feature_hyperparams = dict(\n",
        "    model_nr = 1,\n",
        "\n",
        "    # Models to choose from [mlp, bilstm]\n",
        "    model = \"bilstm\",\n",
        "\n",
        "    train_data_path   = 'train_unshuffle_data.npy',\n",
        "    train_labels_path = 'train_unshuffle_labels.npy',\n",
        "    val_data_path     = 'val_data.npy',\n",
        "    val_labels_path   = 'val_labels.npy',\n",
        "    test_data_path    = 'test_data.npy',\n",
        "    test_labels_path  = 'test_labels.npy',\n",
        "    bidirectional    = True,\n",
        "    lr               = 2e-2,\n",
        "    wd               = 5e-6,\n",
        "    dropout_prob     = 0.1,  \n",
        "    num_layers       = 4,\n",
        "    hidden_size      = 300,  \n",
        "    num_classes      = nr_image_features, #? (same as extractec image features)\n",
        "    embiddings_num   = nr_eeg_features,  #  (same as number of features extracted from EEG_Net)\n",
        "    batch_size       = 128,\n",
        "    patience         = 1,\n",
        "    scheduler_factor = 0.5,\n",
        "    num_epochs       = 50,\n",
        "    mlp_layers       = [128, 64, 40]\n",
        ")\n",
        "\n",
        "EEG_Image_Map, feature_data_loaders, val_acc_hist = model_pipeline_EEG_Image_Map(feature_hyperparams)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f71761ad4f20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mnum_layers\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mhidden_size\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mnum_classes\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mnr_image_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#? (same as extractec image features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0membiddings_num\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mnr_eeg_features\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m#  (same as number of features extracted from EEG_Net)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mbatch_size\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nr_image_features' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsPwA-QsZ-0o"
      },
      "source": [
        "# Evaluate System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTzhQYn2eFfh"
      },
      "source": [
        "def evaluate_system(verbose=True):\n",
        "    # Evaluate EEG-Net\n",
        "    _, _, eeg_acc = test_EEG_Net(EEG_Net, EEG_data_loaders['test'])\n",
        "\n",
        "    # Evaluate Image-Net\n",
        "    _, _, image_acc = test_Image_Net(Image_Net, Image_data_loaders['test'])\n",
        "\n",
        "    # Evaluate EEG-Image-Map\n",
        "    feature_out, feature_loss = test_EEG_Image_Map(feature_data_loaders['test'])\n",
        "    feature_out = [item for sublist in feature_out for item in sublist]\n",
        "\n",
        "    feature_id_acc = calc_feature_id_acc(feature_out, feature_data_loaders['test'])\n",
        "\n",
        "    if verbose:\n",
        "        print('EEG-Net test accuracy:', eeg_acc)\n",
        "        print('Image-Net test accuracy:', image_acc)\n",
        "        print('EEG-Image-Map test loss:', feature_loss)\n",
        "        print('EEG-Image-Map identification accuracy:', feature_id_acc)\n",
        "\n",
        "    return eeg_acc, image_acc, feature_loss, feature_id_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBQvVxUgZ9-f"
      },
      "source": [
        "evaluate_system()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}